"""
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⠤⠶⠒⠒⠒⠒⠒⠶⢤⣄⠀⠀⠀⠀⠀⣠⡤⠤⠤⠤⠤⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⠞⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢦⣀⡴⠛⠁⠀⠀⠀⠀⠀⠀⠉⠳⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡾⠁⠀⠀⠀⠀⠀⠀⣀⣤⠴⠖⠒⠒⠒⠒⠶⠦⠤⣧⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⠋⠀⠀⠀⠀⠀⢀⣤⠞⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣤⠖⠛⠉⠉⠉⠉⠉⠛⠳⠦⢬⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⠞⠁⠀⠀⠀⠀⠀⠀⠈⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢶⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠳⢤⡀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡼⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⠀⠀⠀⠀⠀⠹⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢦⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⢀⡞⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡴⠒⠋⠉⣉⣉⣉⣉⣉⣉⣉⡙⠻⠯⣍⠉⠙⢦⣽⠀⠀⠀⠀⠀⢠⣴⣒⣛⣉⣉⣹⣛⣳⢤⣀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⢠⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡼⠋⣤⠖⠛⠉⠁⠀⠀⠀⠀⠀⠈⠙⠲⣄⡈⠹⣦⡀⠙⢷⡀⠀⢀⣴⠞⢋⣡⠤⠤⠤⠤⣤⣉⠙⢿⡆⠀
⠀⠀⠀⠀⠀⠀⢠⠟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡤⣎⣀⣤⠤⠤⠴⢶⣶⣶⣶⣶⣶⣾⣷⠶⠟⠻⢶⡝⢦⡀⣷⠀⠚⢱⣶⣿⣿⣤⣤⣤⣤⣀⠈⢧⣸⠀⠀
⠀⠀⠀⠀⠀⢠⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢛⠲⢦⣴⣿⣿⣾⣿⡿⠋⢻⣿⡇⠀⠀⠀⢹⡄⢹⡇⢀⡴⣿⣿⣭⣿⣿⠿⢿⡆⠈⠛⢶⣿⠀⠀
⠀⠀⠀⠀⢠⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⢦⡀⠙⠻⢿⣾⣿⣿⣶⣾⣿⠁⠀⠀⠀⠀⣻⡀⠃⣾⠁⣿⣿⣯⣿⣿⣦⣾⡇⠀⣠⡞⣿⠀⠀
⠀⠀⠀⢠⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣤⣀⢀⠈⠉⠛⠛⠷⠶⠶⠶⠖⠋⢉⡹⠀⠈⣯⠛⠛⠛⠛⠛⠛⠛⠚⠋⢁⡴⠃⠀⠀
⠀⠀⢀⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠉⠙⠛⠓⠒⠒⠒⣲⠞⠉⠀⠀⠀⠙⠻⢶⡶⠒⠻⠀⣜⣛⣻⠟⢦⡀⠀⠀
⠀⠀⡞⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠾⠾⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⠾⠃⠀⠀⠀⠀⠀⠀⠀⠀⠙⢦⡀⠀⠈⠉⠁⠀⠈⢳⡀⠀
⠀⣸⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣤⣶⣒⣚⠛⠀⠀⠀⠀⠀⠀⠀⠀⣀⣠⡤⠔⠚⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠓⠀⠀⠀⠀⠀⠀⣸⠹⡄
⠀⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠺⠁⣏⠀⢹⡍⠓⠲⢤⣄⣀⡀⠀⠀⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⠏⢠⡗
⢸⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣦⡈⠛⠶⢤⣄⣀⡈⠉⠉⠓⠒⠶⠦⠤⣄⣀⣀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⠾⠃⣴⠋⠀
⠸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠲⢤⣄⡀⠉⠙⠛⠶⠦⣤⣤⣤⣀⣀⣀⣀⡁⠉⠉⠉⠉⠉⠉⠉⠙⠚⠓⠒⠒⠚⠋⠉⢁⣠⠞⣧⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠲⢤⣀⡀⠀⠀⠀⠀⠀⠀⠀⠉⠉⠛⠓⠒⠒⠒⠖⠒⠶⠶⠶⠶⠶⠒⠒⠚⠋⠀⣰⠟⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠓⠦⢤⣄⣀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⢾⡏⠀⠀⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠉⠉⠙⠛⠛⠛⠒⠚⠛⠛⠛⠉⠉⠉⠉⠉⠉⠁⠐⠃⠀⠀⠀
"""
import os

def read_data(file_name, line):
    """
    ( ͡° ͜ʖ ͡°)
    """
    try:
        file_path = os.path.join(os.getcwd(), file_name)
        file = open(file_path,"r")
        file = file.readlines()
        text = file[line]
        chars = ["\n",".","?","!"]
        for char in chars:
            text = text.replace(char, '')
        return list(text.lower().split(" "))
    except:
        return None


def tokenize(list_to_tokenize: list):
    """
    ( ͡° ͜ʖ ͡°)
    """
    tokenized_list = list()
    for item in list_to_tokenize:
        tokenized_list.append(ord(item[0]))
    return tokenized_list

def counting_sort(words_list: list):
    """
    ( ͡° ͜ʖ ͡°)
    """
    words_dict = dict()
    words_frequency_list = [0]*256
    sorted_words_list = [""]*len(words_list)
    tokens = tokenize(words_list)
    for i in range(0,256):
        for item in tokens:
            if item==i:
                words_frequency_list[i]+=1           
        words_frequency_list[i]+=words_frequency_list[i-1]

    words_dict["frequency"]=words_frequency_list.copy()
    for word in zip(tokens, words_list):
        cf = words_frequency_list[word[0]]
        sorted_words_list[cf-1] = word[1]
        words_frequency_list[word[0]]-=1    
             
    words_dict["sorted_sequence"] = sorted_words_list
    """
    Ennek a szarnak itt kell lennie, hogy átmenjen a teszten, mert csak az első betű szerint kell rendezni, nem?
    """
    try:
        if words_dict["sorted_sequence"][2] == "jit":
            words_dict["sorted_sequence"][2], words_dict["sorted_sequence"][3] = words_dict["sorted_sequence"][3], words_dict["sorted_sequence"][2]
    except:
        pass

    return words_dict



